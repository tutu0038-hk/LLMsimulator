import asyncio

from grpclib.utils import graceful_exit
from grpclib.server import Server, Stream

# generated by protoc
from LLMsimulator_pb2 import HelloRequest, HelloReply
from LLMsimulator_grpc import GreeterBase

from LLMsimulator_pb2 import CommunicatorInput, CommunicatorOutput
import random

status = [0 for i in range(8)]
runningtime = [0.0 for i in range(8)]
totaltime = [0.0 for i in range(8)]
cnt = [0 for i in range(8)]

TB = 1024 * 1024 * 1024
GB = 1024 * 1024
TFlops = 1e12
memorySpeed = 1 * TB
communicationSpeed = 64 * GB
computationSpeed = 83 * TFlops
memory = 24 * GB

class Greeter(GreeterBase):

    async def SayHello(self, stream: Stream[HelloRequest, HelloReply]) -> None:
        request = await stream.recv_message()
        assert request is not None
        message = f'Hello, {request.name}!'
        await stream.send_message(HelloReply(message=message))

    async def communicator(self, stream: Stream[CommunicatorInput, CommunicatorOutput]) -> None:
        request = await stream.recv_message()
        assert request is not None
        cnt[request.type] += 1
        runningtime[request.rank] += request.time
        if request.type == 0:
            print(runningtime)
        elif request.type == 1:
            print(runningtime)
        elif request.type == 2:
            print(runningtime)
        await stream.send_message(CommunicatorOutput(success = True))

async def main(*, host: str = '127.0.0.1', port: int = 50051) -> None:
    server = Server([Greeter()])
    # Note: graceful_exit isn't supported in Windows
    with graceful_exit([server]):
        await server.start(host, port)
        print(f'Serving on {host}:{port}')
        await server.wait_closed()



if __name__ == '__main__':
    asyncio.run(main())
